{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4152064-1660-4df0-a768-50eb2dad3813",
   "metadata": {},
   "source": [
    "#First Program\n",
    "this is our first program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60415aec-84cf-4c3e-9659-14d2e22943f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad code\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3ac89c6-dce2-4ed6-9d7c-dfaeb8642c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nasdas\\nasd\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Going to read high popularity spotify data\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6ecb74-4bec-4a16-aa72-98074bb6159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Dug\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1ccf43-5a0d-4ad5-9648-4e52fabc88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = spark.read.text(\"C:/Users/saul2/OneDrive/Desktop/PastProjects/Pipeline_Project/high_popularity_spotify_data.csv\")\n",
    "df.createOrReplaceTempView(\"Popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bd7f34-cbfb-488b-a15e-e4897564f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|energy,tempo,danc...|\n",
      "|0.592,157.969,0.5...|\n",
      "|0.507,104.978,0.7...|\n",
      "|0.808,108.548,0.5...|\n",
      "|0.91,112.966,0.67...|\n",
      "|0.783,149.027,0.7...|\n",
      "|0.582,116.712,0.7...|\n",
      "|0.561,150.069,0.6...|\n",
      "|0.247,148.101,0.4...|\n",
      "|0.416,94.926,0.49...|\n",
      "|0.722,119.973,0.7...|\n",
      "|0.667,130.019,0.7...|\n",
      "|0.586,107.071,0.6...|\n",
      "|0.806,104.032,0.6...|\n",
      "|0.709,81.012,0.72...|\n",
      "|0.757,139.982,0.7...|\n",
      "|0.917,100.987,0.5...|\n",
      "|0.787,109.939,0.7...|\n",
      "|0.843,122.064,0.6...|\n",
      "|0.406,115.94,0.53...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlQuery1 = spark.sql(\"SELECT * FROM Popularity\")\n",
    "sqlQuery1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a20eaca2-2e47-4156-ab21-8e15e8b71403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-----------+------------+\n",
      "|STUDENT_ID|FIRST_NAME|LAST_NAME|FINAL_SCORE|Letter_Grade|\n",
      "+----------+----------+---------+-----------+------------+\n",
      "|     S3137|      Liam| Williams|      40.01|           F|\n",
      "|     S3284|      Sara|  Johnson|      40.01|           F|\n",
      "|     S4139|      Omar|    Smith|      40.01|           F|\n",
      "|     S4226|     Ahmed|  Johnson|      40.01|           F|\n",
      "|     S4516|      John|    Jones|      40.01|           F|\n",
      "|     S1579|      Sara|    Davis|      40.07|           F|\n",
      "|     S5044|      Omar|    Brown|      40.07|           F|\n",
      "|     S2755|      Liam|    Smith|      40.09|           F|\n",
      "|     S2120|      Sara|    Jones|      40.09|           F|\n",
      "|     S1384|     Ahmed|    Jones|       40.1|           F|\n",
      "|     S2124|      Emma|    Smith|      40.19|           F|\n",
      "|     S2420|       Ali|    Jones|       40.2|           F|\n",
      "|     S2699|      Liam|    Smith|       40.2|           F|\n",
      "|     S5739|      Liam|    Smith|      40.21|           F|\n",
      "|     S3737|      Sara|  Johnson|      40.26|           F|\n",
      "|     S2392|      Liam| Williams|      40.27|           F|\n",
      "|     S5667|      Sara|    Brown|      40.28|           F|\n",
      "|     S3382|      Sara|    Brown|      40.32|           F|\n",
      "|     S4750|      John|    Brown|      40.32|           F|\n",
      "|     S2724|      Sara|    Jones|      40.33|           F|\n",
      "+----------+----------+---------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "df1 = spark.read.json(\"C:/Users/saul2/OneDrive/Desktop/Spark/archive/Students_Grading_Dataset.json\", multiLine=True)\n",
    "df1.createOrReplaceTempView(\"Grading\")\n",
    "df1.withColumn\n",
    "sqlQuery = '''\n",
    "    SELECT STUDENT_ID, FIRST_NAME, LAST_NAME, FINAL_SCORE,\n",
    "        CASE WHEN FINAL_SCORE >= 90 THEN 'A'\n",
    "            WHEN FINAL_SCORE >= 80 THEN 'B'\n",
    "            WHEN FINAL_SCORE >= 70 THEN 'C'\n",
    "            WHEN FINAL_SCORE >= 60 THEN 'D'\n",
    "            ELSE 'F'\n",
    "            END Letter_Grade\n",
    "    FROM Grading \n",
    "    ORDER BY FINAL_SCORE\n",
    "    '''\n",
    "sqlQuery1 = spark.sql(sqlQuery)\n",
    "sqlQuery1.show()\n",
    "#df1.write.mode(\"overwrite\").parquet(\"C:/Users/saul2/OneDrive/Desktop/Spark/output/students_transformed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48977b0f-c482-4200-9a34-b4236ef77371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created: messy_students.csv\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Student_ID\": [\"S1001\", \"S1002\", \"S1003\", \"S1004\", \"S1005\", \"S1006\", \"S1007\"],\n",
    "    \"First_Name\": [\"omar\", \"Maria\", \"Li \", \"Aisha\", \"omar\", \"James\", \"Linda\"],\n",
    "    \"Last_Name\": [\"Williams\", \"Brown\", \"Chan\", \"Smith\", \"Williams\", \"Garcia\", \" \"],\n",
    "    \"Gender\": [\"Male\", \"FEMALE\", \"Male\", \"female\", \"Male\", \"MALE\", \"Female\"],\n",
    "    \"Age\": [22, 18, 20, 21, 22, None, 19],\n",
    "    \"Department\": [\"  Mathematics \", \"Business\", \"Computer Science\", \"  engineering\", \"Mathematics\", \"Biology\", \"Mathematics\"],\n",
    "    \"Attendance (%)\": [97.3, None, 85.0, 90.2, 97.3, 78.5, 91.4],\n",
    "    \"Study Hours\": [10.5, 27.1, None, 12.0, 10.5, 8.5, 9.0],\n",
    "    \"Internet Access\": [\"yes\", \"No\", \"Yes\", \" YES\", \"yes\", \"no\", \"yes\"],\n",
    "    \"Grade\": [\"C\", \"F\", \"B\", \"A\", \"C\", \"D\", \"A\"]\n",
    "}\n",
    "df_messy = pd.DataFrame(data)\n",
    "df_messy.to_csv(\"messy_students.csv\", index=False)\n",
    "print(\"CSV created: messy_students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50095123-3886-4bfc-8ca6-44911440b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student_ID First_Name Last_Name  Gender   Age        Department  \\\n",
      "0      S1001       omar  Williams    Male  22.0      Mathematics    \n",
      "1      S1002      Maria     Brown  FEMALE  18.0          Business   \n",
      "2      S1003        Li       Chan    Male  20.0  Computer Science   \n",
      "3      S1004      Aisha     Smith  female  21.0       engineering   \n",
      "4      S1005       omar  Williams    Male  22.0       Mathematics   \n",
      "5      S1006      James    Garcia    MALE   NaN           Biology   \n",
      "6      S1007      Linda            Female  19.0       Mathematics   \n",
      "\n",
      "   Attendance (%)  Study Hours Internet Access Grade  \n",
      "0            97.3         10.5             yes     C  \n",
      "1             NaN         27.1              No     F  \n",
      "2            85.0          NaN             Yes     B  \n",
      "3            90.2         12.0             YES     A  \n",
      "4            97.3         10.5             yes     C  \n",
      "5            78.5          8.5              no     D  \n",
      "6            91.4          9.0             yes     A  \n"
     ]
    }
   ],
   "source": [
    "print(df_messy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ece7ff-8e20-4d69-95a4-c6b4e558c721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (PySpark)",
   "language": "python",
   "name": "pyspark313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
